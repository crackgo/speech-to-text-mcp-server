# GPU 加速语音转录使用指南

## 🎉 GPU 支持已成功启用！

✅ **GPU 信息**
- 型号：NVIDIA GeForce GTX 1060 6GB
- CUDA 版本：12.4
- PyTorch 版本：2.6.0+cu124

✅ **性能提升**
- CPU 处理：16.2分钟音频 → 26分钟
- GPU 处理：16.2分钟音频 → **19分钟** ⚡
- 性能提升：约 **36%** 加速

---

## 📌 推荐使用方法

### 1. 快速转录（无说话人分离）

使用 `quick_test.py` 进行转录，**自动使用 GPU**，无需额外设置：

```powershell
# 中文音频
python quick_test.py "音频文件路径.mp3" zh

# 英文音频
python quick_test.py "音频文件路径.mp3" en

# 自动检测语言
python quick_test.py "音频文件路径.mp3"
```

**特点：**
- ✅ 自动使用 GPU 加速
- ✅ 支持所有常见音频格式（MP3/WAV/M4A/FLAC 等）
- ✅ 自动保存结果为 .txt 文件
- ✅ 带时间戳的详细输出
- ⚠️ 不包含说话人分离（速度最快）

---

### 2. 说话人分离转录 ⭐

使用 `diarize_test.py` 进行带说话人识别的转录：

```powershell
# 中文会议录音（自动识别多个说话人）
python diarize_test.py "会议录音.mp3" zh

# 英文对话
python diarize_test.py "interview.mp3" en
```

**特点：**
- ✅ 自动识别不同说话人（SPEAKER_01, SPEAKER_02, ...）
- ✅ 为每段对话标注说话人和时间戳
- ✅ 适合多人会议、访谈等场景
- ✅ GPU 加速，性能优秀
- ⚠️ 处理时间比普通转录稍长（增加约 30%）

**输出示例：**
```
[说话人 SPEAKER_01]
[00:00:10.000 --> 00:00:15.000]
大家好，今天我们讨论产品需求...

[说话人 SPEAKER_02]
[00:00:15.500 --> 00:00:20.000]
关于这个问题，我有几点建议...
```

---

### 3. 批量转录

处理整个文件夹的音频文件：

```powershell
python batch_transcribe.py "E:\音频文件夹" zh
```

**特点：**
- 自动扫描文件夹内所有音频文件
- 显示进度和统计信息
- 跳过已处理的文件

---

## 🔧 说话人分离状态

✅ **已成功启用！** 说话人分离功能现已可用
- 已安装：NumPy 1.26.4（兼容版本）
- pyannote.audio 3.1.0 正常工作
- pyannote.pipeline 3.0.1 已配置
- 支持自动识别多个说话人

**使用方法：**
```powershell
# 带说话人分离的转录
python diarize_test.py "音频文件.mp3" zh
```

**识别效果：**
- 自动区分不同说话人（SPEAKER_01, SPEAKER_02, ...）
- 为每段对话标注说话人和时间戳
- 支持多人会议录音分析

---

## 💡 使用示例

### 示例 1：转录会议录音
```powershell
python quick_test.py "C:\Users\huang\Desktop\会议录音.mp3" zh
```

**输出：**
- 控制台显示实时进度
- 自动保存到 `C:\Users\huang\Desktop\会议录音.txt`
- 包含时间戳的完整转录文本

### 示例 2：批量处理
```powershell
# 处理整个文件夹
python batch_transcribe.py "D:\录音文件" zh

# 输出示例：
# 扫描到音频文件: 15
# 处理中: file1.mp3 (1/15)
# 处理中: file2.mp3 (2/15)
# ...
# 完成! 成功: 15, 失败: 0
```

---

## 📊 性能对比

| 音频时长 | CPU 处理时间 | GPU 处理时间 | 加速比 |
|---------|------------|------------|-------|
| 16.2分钟 | 26分钟 | 19分钟 | 1.36x |
| 30分钟（预估） | 48分钟 | 35分钟 | 1.37x |
| 60分钟（预估） | 96分钟 | 70分钟 | 1.37x |

---

## 🚀 最佳实践

1. **音频文件**
   - 支持格式：MP3, WAV, M4A, FLAC, OGG, WMA
   - 推荐时长：最长 60 分钟
   - 音质越好，识别准确率越高

2. **语言选择**
   - 中文：使用 `zh`
   - 英文：使用 `en`
   - 日语：使用 `ja`
   - 不确定：留空自动检测

3. **GPU 优化**
   - GPU 会自动使用，无需手动设置
   - 确保显卡驱动是最新版本
   - 处理长音频时关闭其他 GPU 占用程序

4. **错误处理**
   - 如遇到 CUDA 内存不足：尝试重启 Python 进程
   - 如转录结果不准确：检查音频质量和语言设置

---

## 🛠️ 验证 GPU 是否启用

运行以下命令检查：

```powershell
python -c "import torch; print('CUDA:', torch.cuda.is_available()); print('GPU:', torch.cuda.get_device_name(0))"
```

**期望输出：**
```
CUDA: True
GPU: NVIDIA GeForce GTX 1060
```

---

## 📝 技术细节

### 已安装的组件
- ✅ PyTorch 2.6.0+cu124 (GPU 版本)
- ✅ OpenAI Whisper (medium 模型)
- ✅ FFmpeg 8.0
- ✅ pydub (音频格式转换)
- ✅ pyannote.audio 3.1.0 (说话人分离)
- ✅ pyannote.pipeline 3.0.1
- ✅ NumPy 1.26.4 (兼容版本)

### CUDA 配置
```
CUDA 版本: 12.4
驱动版本: 551.23
显存: 6144MB
```

---

## ❓ 常见问题

**Q: 为什么 GPU 加速不明显？**
A: GTX 1060 是较老的显卡，加速效果有限。新一代 RTX 显卡会有更好的效果。

**Q: 可以处理超过 60 分钟的音频吗？**
A: 可以，但处理时间会成比例增长。建议分段处理长音频。

**Q: 转录准确率如何提高？**
A: 
1. 使用高质量音频（无杂音、清晰）
2. 正确选择语言代码
3. 音频中语速适中、发音清晰

**Q: 说话人分离准确吗？**
A: 
- 准确率通常在 85-95% 之间
- 效果受音频质量影响（清晰度、背景噪音）
- 说话人声音差异越大，识别越准确
- 建议使用高质量录音设备

**Q: 说话人分离何时可用？**
A: ✅ 已可用！使用 `diarize_test.py` 即可进行带说话人分离的转录。

---

## 📌 下一步计划

1. ✅ ~~安装 GPU 支持~~ (已完成)
2. ✅ ~~验证 GPU 性能~~ (已完成)
3. ✅ ~~解决说话人分离依赖冲突~~ (已完成)
4. ⏳ 优化说话人分离准确率
5. ⏳ 集成 Cherry Studio MCP 服务器

---

**更新时间：** 2025-11-18 17:00  
**GPU 状态：** ✅ 已启用并验证  
**说话人分离：** ✅ 已成功启用
